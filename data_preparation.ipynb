{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier nettoyé dans un DataFrame\n",
    "df_clean = pd.read_csv('house_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.537589636826278"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_clean[\"prix_vente\"]\n",
    "X = df_clean.drop([\"date_vente\", \"id\",\"nb_etage\" ,\"vue_sur_mer\", \"qualite_vue\", \"superficie_sur_sol\", \"superficie_sous_sol\", \"annee_construction\", \"annee_renovation\", \"code_postal\",\"surface_totale15\"], axis=1)\n",
    "# Séparer les données en deux parties: entraînement et test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Créer une pipeline de données pour automatiser le processus de préparation des données\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "# # Spécifier les colonnes pour la transformation de feature\n",
    "# num_features = ['surface_habitable', 'surface_totale', 'nb_sdb', 'surface_habitable15', 'qualite_globale', 'longitude', 'latitude']\n",
    "\n",
    "# # Créer une instance de la classe ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), num_features), # Normalisation\n",
    "#         ('poly', PolynomialFeatures(degree=2), num_features) # Création de variables polynomiales\n",
    "#     ])\n",
    "\n",
    "# # Créer la pipeline de données en chaînant les étapes de prétraitement\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor)\n",
    "# ])\n",
    "\n",
    "# # Appliquer la pipeline de préparation de données sur le jeu de données d'entraînement\n",
    "# train_prepared = pipeline.fit_transform(train_data)\n",
    "\n",
    "# # Créer un DataFrame à partir du jeu de données préparé\n",
    "# df_train_prepared = pd.DataFrame(train_prepared, columns=pipeline['preprocessor'].get_feature_names())\n",
    "\n",
    "# # Sauvegarder le jeu de données préparé sous forme de fichier CSV\n",
    "# df_train_prepared.to_csv('house_data_prepared.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8364543934568593"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_clean['prix_vente']\n",
    "X = df_clean[[\"surface_habitable\",\"nb_sdb\",\"qualite_globale\",\"latitude\",\"longitude\",\"surface_totale\",\"vue_sur_mer\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,random_state=42)\n",
    "\n",
    "# pre-processing de X_train\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "X_train_min_max = minmax.fit_transform(X_train)\n",
    "\n",
    "# Entrainement sur X_train\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=4)\n",
    "trained_model = model.fit(X_train_min_max,y_train)\n",
    "\n",
    "# pre-processing de X_test\n",
    "X_test_min_max = minmax.transform(X_test)\n",
    "\n",
    "# scoring\n",
    "trained_model.score(X_test_min_max,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8364543934568593"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_clean['prix_vente']\n",
    "X = df_clean[[\"surface_habitable\",\"nb_sdb\",\"qualite_globale\",\"latitude\",\"longitude\",\"surface_totale\",\"vue_sur_mer\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "knn_4 = KNeighborsRegressor(n_neighbors=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "     ('minmax', minmax),\n",
    "     ('knn', knn_4)\n",
    "])\n",
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15136054, 0.28125   , 0.58333333, ..., 0.29651163, 0.00719161,\n",
       "        0.        ],\n",
       "       [0.22193878, 0.375     , 0.58333333, ..., 0.19435216, 0.0053338 ,\n",
       "        0.        ],\n",
       "       [0.29591837, 0.3125    , 0.83333333, ..., 0.32392027, 0.00890941,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.18231293, 0.3125    , 0.58333333, ..., 0.19601329, 0.00333255,\n",
       "        0.        ],\n",
       "       [0.16666667, 0.21875   , 0.58333333, ..., 0.33305648, 0.00823517,\n",
       "        0.        ],\n",
       "       [0.19387755, 0.3125    , 0.58333333, ..., 0.18521595, 0.00940758,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_pipe[\"minmax\"].transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apprenant/miniconda3/envs/machine_learning/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8483756101087857"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_clean['prix_vente']\n",
    "X = df_clean[[\"surface_habitable\",\"nb_sdb\",\"qualite_globale\",\"latitude\",\"longitude\",\"surface_totale\",\"vue_sur_mer\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# On cree un pipeline de proprocessing pour les variables numériques\n",
    "numeric_features = [\"surface_habitable\",\"nb_sdb\",\"surface_totale\",\"latitude\",\"longitude\"]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('stdscaler', MinMaxScaler()),  # moyenne nulle et écart type = 1 -> Reg, SVM, PCA\n",
    "        ])\n",
    "\n",
    "# On cree un pre-processeur pour les variables catégorielles\n",
    "categorial_features = [ \"qualite_globale\",\"vue_sur_mer\"]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder(sparse=True)\n",
    "\n",
    "\n",
    "# a l'aide de la classe ColumnTransformer, \n",
    "# on déclare à quelles variables on applique quel transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorial_features)\n",
    "    ]\n",
    ")\n",
    "#On obtient un pipeline de preprocessing qu'on peut utiliser dans un pipeline d'entainement\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_4 = KNeighborsRegressor(n_neighbors=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('knn', knn_4)\n",
    "])\n",
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6372ac1f96e6a574de8fb7db2482e4b51a9c7365ff441969ce58324c2dcfaf16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
